---
title: "Summary: Radical Uncertainty by John Kay and Mervyn King"
date: "2020-10-25"
categories: 
  - "bookshelf"
---

[

\>

<img src="https://images.squarespace-cdn.com/content/v1/5e9e54ba9225353212ce08ab/1603646101578-5B93EBKWDU0C628Q60GZ/ke17ZwdGBToddI8pDm48kKYfOagNqMYNbM6xqqZpkF1Zw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVHgRdpW7zhNmEkE96WCEB59KJKeKn2Obr42QoJ0UNOFwdqa3S12oG7JiiZSdk0r0e4/51edjQBpSDL.\_SX328\_BO1%2C204%2C203%2C200\_.jpg" alt="51edjQBpSDL.\_SX328\_BO1,204,203,200\_.jpg" />

](https://www.amazon.ca/Radical-Uncertainty-Decision-Making-Beyond-Numbers/dp/1324004770)

[](https://www.amazon.ca/Radical-Uncertainty-Decision-Making-Beyond-Numbers/dp/1324004770)

John Kay and Mervyn King's book _Radical Uncertainty: Decision-Making Beyond the Numbers_ is a long book that nevertheless delivers a very clear message. Kay, the first dean at Oxford's Said Business School, and King, former Governor of the Bank of England, take issue with economics' fixation with probabilistic thinking. Like Shiller's [_Narrative Economics_](https://mobydiction.ca/blog/review-shiller-narrative-economics), Kay and King argue that there is more to economics than data and algorithms, and suggest that focusing too narrowly on quantitative data has diminished the field's practical utility in the world.

As I noted when summarizing _Narrative Economics_ I want to emphasize that I'm not an economist. So, what stood out to me from this book will likely be very different from someone who is better versed in that "dismal science." Nevertheless, I think there are a few generalizable points in this book that are worth summarizing for anyone who has to work under conditions of uncertainty (which is nearly everyone).

## What is radical uncertainty?

Kay and King use the term "radical uncertainty" to describe a state of uncertainty that is characterized by both non-stationarity—that is, things change a lot—and by reflexivity, meaning that conditions may change in response to our beliefs about it.

They differentiate radical uncertainty from resolvable uncertainty. Resolvable uncertainty has a clear solution state. That is, we can look up a verifiable fact to answer the question, or we can describe the situation using probability. The result of the role of a die is resolvable uncertainty: we know there are a defined number of possible outcomes and can assign odds to each. In contrast, situations of radical uncertainty may involve not only results that we did not expect, but results we could not have even anticipated.

## Radical uncertainty and probabilistic thinking

It's dangerous, Kay and King argue, to try to use probabilistic thinking to describe environments of radical uncertainty. These include business, politics and finance, none of which are governed by scientific law. Rather, they are the product of countless agents and actors, none of whom perform actions that are necessarily rational or optimal.

Instead of asking the odds of any event happening, Kay and King say that we should ask, "What is going on here?" We must look for "thick description," not probabilities, to help us make decisions and choose actions.

But, they say, this is not what many economists do. Instead, they rely on mathematical models and algorithms to try to predict or forecast the likelihood of various events occurring. According to Kay and King, they extrapolate from small-world models to larger-scale patterns. But, this is faulty logic. In many cases, these small-world models are based on faulty assumptions, such as that people are rational actors seeking optimal outcomes.

In reality, people cannot be rational actors. They simply lack the information and context that would be required to act "rationally" under conditions of radical uncertainty. As a result, they rely on heuristics and biases that enable them to quickly filter out some information and arrive at a satisfactory conclusion given whatever constraints might exist.

## Critique of behavioural economics

This leads to Kay and King's critique of behavioural economics. They suggest that behavioural economists are too dismissive of "irrational" decision making that may result from cognitive biases. The kinds of experiments that "prove" that people do not or cannot make optimal decisions, they say, can't be used to make larger claims about the efficacy of our decision making; when you ask a subject to make a choice as part of an economics experiment, the environment is too distant from a real-world setting in which the agent must consider contexts far more complex than a simple experimental apparatus. What appears irrational in a lab setting may be a very rational decision-making process in a real-world setting that is characterized by radical uncertainty. As Kay and King put it, "real households, real businesses, and real governments do not optimize; they cope."

And so, dismissing cognitive biases as sub-optimal assumes that there is some objectively correct or rational answer, but in many decision-making domains, there's not. Dismissing these important decision-making faculties as errors in thinking assumes that there are always logical, rational decision available to us. This might be the case in the kinds of small-world experiments that behavioural economists often rely on, but in many cases these experiments can't be extrapolated into the larger, more complex world in which we operate.

Kay and King are therefore skeptical of folks like Daniel Kahnemann who suggest that we turn to algorithms whenever possible to mitigate the risks that come from heuristics and biases. They point out that many—most?—decisions cannot be reduced to numbers and probabilistic thinking. Indeed, in many cases this kind of reasoning can be dangerous: in the absence of "thick description" to accompany the numbers, we create the risk that evidence-based policy becomes policy-based evidence. That is, the numbers will measure, reflect, and then amplify underlying conditions in a kind of feedback loop that reifies structures of discrimination and inequality. People, in other words, are not their statistical distribution, and policy should reflect that.

If algorithms were actually inherently more reliable than other modes of thinking, they suggest, we likely would have evolved to think more like computers rather than having to invent them.

## Narratives as tools for thought

So how can we make decisions under conditions of radical uncertainty? Kay and King argue that narratives have important roles to play.

Far from being deceptive, narratives in fact are vital tool in our decision-making processes. Narratives help us make decisions in which probability judgments are not feasible due to uncertainty. We use metaphor, analogy, and other linguistic tools to better understand and make sense of a situation, and to make what is abstract more concrete. It helps us answer the question of "what is going on here?" We need narratives to help us make sense of facts—even (or perhaps especially) when we there is quantitative or mathematical data available.

But, it is dangerous to think that one narrative can be applied universally. Rather, our reference narratives must undergo continual revision as we ingest new information. People often want an overarching grand narrative that they can apply to any complex situation, but domains of radical uncertainty are both non-stationary and complex. They themselves are in constant flux, and may change in response to the narratives we create about them.

Narratives mean more than just stories; narratives include models other tools for thought that suppose fictional agents acting under hypothetical conditions.

For a narrative to resonate effectively, it must be both credible and coherent. This means that it must be presented in a fashion such that it is trustworthy and believable and it must be consistent internally as well as with external information and reference narratives available to its audience.

It does not follow that a narrative has to be true. A fictional narrative can convey reference information that can help people navigate uncertainty. Narratives, after all, generate real-world effects; as well, the kinds of small-world models used by economists to explicate large-world matters are themselves narratives.

Rather than referring to narratives as true or false, we should look to understand them as useful or not. And when they're not, we should be prepared to revise them. After all, Kay and King point out, the hallmark of scientific thinking is not a rigid adherence to deductive reasoning but instead an openness to new information along with the understanding that it may require adjustments to our reference narratives.

## Closing thoughts

As I noted in introducing this book, it's a lot of pages dealing with ideas that probably could have been expressed more succinctly. With that said, there's more to this book than what I've presented here. Kay and King offer some insightful commentary on a few other topics; I found their analysis of insurance as a product that serves to protect reference narratives to be an interesting take. They also offer a critique of "nudging" that is worth considering, suggesting that the concept of a nudge implies that the nudger has a better understanding of context than the person being nudged. If that's not the case, there's going to be a problem.

All in all, though, I found this to be a useful companion to Shiller's _Narrative Economics_ and Madsbjerg's [_Sensemaking_](https://mobydiction.ca/blog/summary-sensemaking-by-christian-madsbjerg). Kay and King take narrative a bit more seriously than Shiller does; Shiller, I think, sees narrative as another example of irrationality whereas Kay and King address it more seriously as playing an important role in our culture. What I do appreciate about _Radical Uncertainty,_ though, is that—like Madsjberg—it offers a compelling case for the humanistic research and ways of seeing the world that considers them not only as valuable but actually useful and vital.
